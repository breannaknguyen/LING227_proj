{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "from datasets import Dataset\n",
    "\n",
    "full = pd.read_csv('aita_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n"
     ]
    }
   ],
   "source": [
    "## Create dataset with just categorical vars\n",
    "df = full.drop(columns = ['id', 'title', 'text', 'ratio', 'comments', 'url', 'op_age', 'target_age', 'length'])\n",
    "df = df[['op_gender', 'target_gender', 'experience', 'relationship', \n",
    "         'industry', 'condition', 'action', 'intention', \n",
    "         'impact', 'good_standing', 'perspective', 'verdict']]\n",
    "\n",
    "train_df  = df.sample(n=84, random_state=42)\n",
    "test_indices = ~df.index.isin(train_df.index)\n",
    "test_df = df[test_indices]\n",
    "\n",
    "def classify_file(filename, df):\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            output = f\"op_gender={row['op_gender']},\" \\\n",
    "                     f\"target_gender={row['target_gender']},\" \\\n",
    "                     f\"experience={row['experience']},\" \\\n",
    "                     f\"relationship={row['relationship']},\" \\\n",
    "                     f\"industry={row['industry']},\" \\\n",
    "                     f\"condition={row['condition']},\" \\\n",
    "                     f\"action={row['action']},\" \\\n",
    "                     f\"intention={row['intention']},\" \\\n",
    "                     f\"impact={row['impact']},\" \\\n",
    "                     f\"good_standing={row['good_standing']},\" \\\n",
    "                     f\"perspective={row['perspective']},\" \\\n",
    "                     f\"{row['verdict']}\\n\"\n",
    "\n",
    "            file.write(output)\n",
    "\n",
    "#classify_file('train.txt', train_df)\n",
    "#classify_file('test.txt', test_df)\n",
    "\n",
    "print(sum(train_df[\"verdict\"]==\"NTA\")/len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same as above but with added features\n",
    "\n",
    "def xml_file_features(df, xml_file):\n",
    "    root = ET.Element(\"dataset\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        item = ET.SubElement(root, \"item\")\n",
    "            \n",
    "        item.set(\"label\", str(row[\"verdict\"]))\n",
    "        item.set(\"title\", str(row[\"title\"]))\n",
    "        item.set(\"op_gender\", str(row[\"op_gender\"]))\n",
    "        item.set(\"target_gender\", str(row[\"target_gender\"]))\n",
    "        item.set(\"experience\", str(row[\"experience\"]))\n",
    "        item.set(\"relationship\", str(row[\"relationship\"]))\n",
    "        item.set(\"industry\", str(row[\"industry\"]))\n",
    "        item.set(\"condition\", str(row[\"condition\"]))\n",
    "        item.set(\"action\", str(row[\"action\"]))\n",
    "        item.set(\"intention\", str(row[\"intention\"]))\n",
    "        item.set(\"impact\", str(row[\"impact\"]))\n",
    "        item.set(\"good_standing\", str(row[\"good_standing\"]))\n",
    "        item.set(\"perspective\", str(row[\"perspective\"]))\n",
    "\n",
    "        content = ET.SubElement(item, \"content\")\n",
    "        content.text = str(row[\"text\"])\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "\n",
    "    xml_str = ET.tostring(root, encoding=\"unicode\")\n",
    "\n",
    "    dom = xml.dom.minidom.parseString(xml_str)\n",
    "    pretty_xml_str = dom.toprettyxml()\n",
    "\n",
    "    with open(xml_file, \"w\") as f:\n",
    "        f.write(pretty_xml_str)\n",
    "\n",
    "train_df  = full.sample(n=74, random_state=42)\n",
    "\n",
    "tmp_indices = ~full.index.isin(train_df.index)\n",
    "tmp = full[tmp_indices]\n",
    "\n",
    "test_df = tmp.sample(n=20, random_state=42)\n",
    "\n",
    "dev_indices = ~tmp.index.isin(test_df.index)\n",
    "dev_df = tmp[dev_indices]\n",
    "\n",
    "\n",
    "#xml_file_features(train_df, \"train.xml\")\n",
    "#xml_file_features(test_df, \"test.xml\")\n",
    "#xml_file_features(dev_df, \"dev.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('aita_dataset.csv')\n",
    "\n",
    "train_df  = dataset.sample(n=74, random_state=42)\n",
    "\n",
    "tmp_indices = ~dataset.index.isin(train_df.index)\n",
    "tmp = dataset[tmp_indices]\n",
    "\n",
    "test_df = tmp.sample(n=20, random_state=42)\n",
    "\n",
    "dev_indices = ~tmp.index.isin(test_df.index)\n",
    "dev_df = tmp[dev_indices]\n",
    "\n",
    "dataset_dict = {\n",
    "    'train': train_df,\n",
    "    'validation': dev_df,\n",
    "    'test': test_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT Overall Accuracy: 61.904761904761905\n",
      "ChatGPT Precision NTA: 88.88888888888889\n",
      "ChatGPT Precision YTA: 41.66666666666667\n",
      "ChatGPT Recall NTA: 53.333333333333336\n",
      "ChatGPT Recall YTA: 83.33333333333334\n",
      "ChatGPT F1 NTA: 66.66666666666667\n",
      "ChatGPT F1 YTA: 55.555555555555564\n",
      "Gemini Overall Accuracy: 61.904761904761905\n",
      "Gemini Precision NTA: 81.81818181818183\n",
      "Gemini Precision YTA: 40.0\n",
      "Gemini Recall NTA: 60.0\n",
      "Gemini Recall YTA: 66.66666666666666\n",
      "Gemini F1 NTA: 69.23076923076924\n",
      "Gemini F1 YTA: 49.99999999999999\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from CSV\n",
    "df = pd.read_csv('aita_data_test.csv')\n",
    "\n",
    "# Calculate overall accuracy\n",
    "gpt_acc = sum(df[\"verdict\"] == df[\"ChatGPT\"]) / len(df) * 100\n",
    "gem_acc = sum(df[\"verdict\"] == df[\"Gemini\"]) / len(df) * 100\n",
    "\n",
    "# Calculate precision for NTA\n",
    "gpt_pre_NTA = sum((df[\"verdict\"] == \"NTA\") & (df[\"ChatGPT\"] == \"NTA\")) / sum(df[\"ChatGPT\"] == \"NTA\") * 100\n",
    "gem_pre_NTA = sum((df[\"verdict\"] == \"NTA\") & (df[\"Gemini\"] == \"NTA\")) / sum(df[\"Gemini\"] == \"NTA\") * 100\n",
    "\n",
    "# Calculate precision for YTA\n",
    "gpt_pre_YTA = sum((df[\"verdict\"] == \"YTA\") & (df[\"ChatGPT\"] == \"YTA\")) / sum(df[\"ChatGPT\"] == \"YTA\") * 100\n",
    "gem_pre_YTA = sum((df[\"verdict\"] == \"YTA\") & (df[\"Gemini\"] == \"YTA\")) / sum(df[\"Gemini\"] == \"YTA\") * 100\n",
    "\n",
    "# Calculate recall for NTA\n",
    "gpt_rec_NTA = sum((df[\"verdict\"] == \"NTA\") & (df[\"ChatGPT\"] == \"NTA\")) / sum(df[\"verdict\"] == \"NTA\") * 100\n",
    "gem_rec_NTA = sum((df[\"verdict\"] == \"NTA\") & (df[\"Gemini\"] == \"NTA\")) / sum(df[\"verdict\"] == \"NTA\") * 100\n",
    "\n",
    "# Calculate recall for YTA\n",
    "gpt_rec_YTA = sum((df[\"verdict\"] == \"YTA\") & (df[\"ChatGPT\"] == \"YTA\")) / sum(df[\"verdict\"] == \"YTA\") * 100\n",
    "gem_rec_YTA = sum((df[\"verdict\"] == \"YTA\") & (df[\"Gemini\"] == \"YTA\")) / sum(df[\"verdict\"] == \"YTA\") * 100\n",
    "\n",
    "# Calculate F1 score for NTA\n",
    "gpt_f1_NTA = (2 * gpt_pre_NTA * gpt_rec_NTA) / (gpt_pre_NTA + gpt_rec_NTA)\n",
    "gem_f1_NTA = (2 * gem_pre_NTA * gem_rec_NTA) / (gem_pre_NTA + gem_rec_NTA)\n",
    "\n",
    "# Calculate F1 score for YTA\n",
    "gpt_f1_YTA = (2 * gpt_pre_YTA * gpt_rec_YTA) / (gpt_pre_YTA + gpt_rec_YTA)\n",
    "gem_f1_YTA = (2 * gem_pre_YTA * gem_rec_YTA) / (gem_pre_YTA + gem_rec_YTA)\n",
    "\n",
    "# Print results\n",
    "print(\"ChatGPT Overall Accuracy:\", gpt_acc)\n",
    "print(\"ChatGPT Precision NTA:\", gpt_pre_NTA)\n",
    "print(\"ChatGPT Precision YTA:\", gpt_pre_YTA)\n",
    "print(\"ChatGPT Recall NTA:\", gpt_rec_NTA)\n",
    "print(\"ChatGPT Recall YTA:\", gpt_rec_YTA)\n",
    "print(\"ChatGPT F1 NTA:\", gpt_f1_NTA)\n",
    "print(\"ChatGPT F1 YTA:\", gpt_f1_YTA)\n",
    "\n",
    "print(\"Gemini Overall Accuracy:\", gem_acc)\n",
    "print(\"Gemini Precision NTA:\", gem_pre_NTA)\n",
    "print(\"Gemini Precision YTA:\", gem_pre_YTA)\n",
    "print(\"Gemini Recall NTA:\", gem_rec_NTA)\n",
    "print(\"Gemini Recall YTA:\", gem_rec_YTA)\n",
    "print(\"Gemini F1 NTA:\", gem_f1_NTA)\n",
    "print(\"Gemini F1 YTA:\", gem_f1_YTA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
